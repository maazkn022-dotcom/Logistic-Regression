{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Supervised Learning: Regression Models and Performance Metrics :-***"
      ],
      "metadata": {
        "id": "7-1lFFXyNRzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "   ANS:- Simple Linear Regression (SLR) is a statistical method that models the relationship between two variables one independent (predictor) and one dependent (response). It fits a straight line, expressed as $Y=\\beta _0+\\beta _1X+\\epsilon$ , where $\\beta _0$ is the intercept, $\\beta _1$ the slope, and $\\epsilon$  the error term.\n",
        "\n",
        "   It helps in predicting the dependent variable's value based on changes in the independent variable. Additionally, it measures the strength and direction of this relationship, offering insights into how variations in the predictor influence outcomes. This makes SLR useful for forecasting, trend analysis, and understanding cause-effect dynamics in data-driven decision-making across diverse fields.\n",
        "\n"
      ],
      "metadata": {
        "id": "nZGh4OMBOefc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "    ANS:-  The key assumptions of Simple Linear Regression are:\n",
        "\n",
        "    - **Linearity:** The relationship between independent and dependent variables is linear.\n",
        "\n",
        "    - **Independence:** Observations are independent of each other.\n",
        "\n",
        "    - **Homoscedasticity:** Constant variance of errors across all levels of the independent variable.\n",
        "\n",
        "    - **Normality:** Residuals are normally distributed.\n",
        "\n",
        "    - **No multicollinearity:** Not relevant in SLR, but predictor should not be correlated with error terms.\n",
        "\n"
      ],
      "metadata": {
        "id": "qkQyfl6tSKvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "ANS :- The mathematical equation for a Simple Linear Regression model is:\n",
        "\n",
        "   $Y=\\beta _0+\\beta _1X+\\epsilon$\n",
        "\n",
        "- Y: Dependent variable (outcome to predict).\n",
        "- X: Independent variable (predictor).\n",
        "- $\\beta _0$: Intercept, value of Y when X=0.\n",
        "- $\\beta _1$: Slope, change in Y for one-unit change in X.\n",
        "- $\\epsilon$ : Error term, capturing random variation unexplained by the model.\n"
      ],
      "metadata": {
        "id": "3hg85G4aTH66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "    ANS :- A real-world example of Simple Linear Regression is predicting house prices based on square footage. Here, square footage acts as the independent variable, while house price is the dependent variable. By fitting a regression line, analysts can estimate how much price increases for each additional unit of area. This helps buyers, sellers, and real estate agents understand market trends, make informed decisions, and forecast property values using a straightforward, interpretable statistical model grounded in linear relationships."
      ],
      "metadata": {
        "id": "WDv_jtRUUaLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Example data: square footage (X) and house price (Y)\n",
        "\n",
        "X = np.array([[1000], [1500], [2000], [2500], [3000]])\n",
        "Y = np.array([200000, 250000, 300000, 350000, 400000])\n",
        "\n",
        "# Fit model\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Predict price for 2200 sq.ft\n",
        "\n",
        "prediction = model.predict([[2200]])\n",
        "print(\"Predicted Price:\", prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL0rDG3lVD90",
        "outputId": "dac52bca-95c4-4275-83e9-7fb00f7c070f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Price: 320000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is the method of least squares in linear regression?\n",
        "\n",
        "    ANS :- The method of least squares in linear regression is a mathematical technique used to estimate regression coefficients. It minimizes the sum of squared differences between observed values and predicted values from the regression line. By finding the line that produces the smallest total squared error it ensures the best possible fit to the data. This method provides unbiased, efficient estimates under classical assumptions, making it the standard approach for parameter estimation in regression analysis.\n",
        "\n",
        "\n",
        "    The least squares method works by minimizing the sum of squared residuals between observed and predicted values.\n",
        "    \n",
        "    Steps:\n",
        "\n",
        "- Assume model: $Y=\\beta _0+\\beta _1X+\\epsilon$\n",
        "- Residuals: $e_i=Y_i-(\\beta _0+\\beta _1X_i)$\n",
        "- Objective: Minimize $S=\\sum e_i^2=\\sum (Y_i-\\beta _0-\\beta _1X_i)^2$\n",
        "- Differentiate $S$ w.r.t. $\\beta _0,\\beta _1$, set derivatives to zero.\n",
        "- Solve equations → obtain optimal $\\beta _0,\\beta _1$"
      ],
      "metadata": {
        "id": "mQGanU5QVdim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "    ANS :- Logistic Regression is a statistical method used for binary classification, modeling the probability that a dependent variable belongs to a category. It uses the logistic (sigmoid) function to constrain outputs between 0 and 1.\n",
        "    \n",
        "    Unlike Linear Regression, which predicts continuous values using a straight line, Logistic Regression predicts categorical outcomes.\n",
        "    \n",
        "    The key difference lies in purpose: Linear Regression estimates numeric relationships, while Logistic Regression estimates probabilities and class membership, making it suitable for classification tasks.\n"
      ],
      "metadata": {
        "id": "uvoChn04Yibn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "    ANS :- Three common evaluation metrics for regression models are:\n",
        "\n",
        "    - **Mean Absolute Error (MAE):** Average of absolute differences between predicted and actual values, showing overall prediction accuracy.\n",
        "\n",
        "    - **Mean Squared Error (MSE):** Average of squared differences, penalizing larger errors more strongly.\n",
        "\n",
        "    - **R-squared (Coefficient of Determination):** Proportion of variance in the dependent variable explained by the model, indicating goodness of fit.\n",
        "    \n",
        "    These metrics assess accuracy, error magnitude, and explanatory power.\n"
      ],
      "metadata": {
        "id": "NAkYP4s0aBe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "    ANS:- The purpose of the R-squared metric is to measure how well a regression model explains the variability of the dependent variable. It represents the proportion of variance in the outcome accounted for by the independent variable(s). Values range from 0 to 1 where higher values indicate better explanatory power. Essentially, R-squared shows the goodness of fit how closely the regression predictions match the actual data, helping assess the model's effectiveness in capturing relationships.\n"
      ],
      "metadata": {
        "id": "89TLvx89ax5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept."
      ],
      "metadata": {
        "id": "4JovMYTebYus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "\n",
        "X = np.array([[1], [2], [3], [4], [5]])   # Independent variable\n",
        "Y = np.array([2, 4, 5, 4, 5])             # Dependent variable\n",
        "\n",
        "# Fit model\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Print slope and intercept\n",
        "\n",
        "print(\"Slope (β1):\", model.coef_[0])\n",
        "print(\"Intercept (β0):\", model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vONovCiVOxL",
        "outputId": "c0dc1550-e525-48fe-c039-f4729ffdf383"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (β1): 0.6\n",
            "Intercept (β0): 2.2\n"
          ]
        }
      ]
    }
  ]
}